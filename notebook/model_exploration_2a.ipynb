{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import joblib\n",
    "import time\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, plot_roc_curve, make_scorer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import lightgbm as lgb\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_knn():\n",
    "    \"\"\"\n",
    "    Function for initiating Logistic Regression Model\n",
    "    \"\"\"\n",
    "\n",
    "    base_model = KNeighborsClassifier()\n",
    "\n",
    "    \n",
    "    return base_model\n",
    "\n",
    "def model_dt():\n",
    "    \"\"\"\n",
    "    Function for initiating Random Forest Model\n",
    "    \"\"\"\n",
    "    \n",
    "    base_model = DecisionTreeClassifier(random_state=42)\n",
    "    \n",
    "    return base_model\n",
    "\n",
    "def model_mlp():\n",
    "    \"\"\"\n",
    "    Function for initiating LightGBM Model\n",
    "    \"\"\"\n",
    "\n",
    "    base_model = MLPClassifier(random_state=42, max_iter=300)\n",
    "    \n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_model(train_log_dict):\n",
    "    max_score = max(train_log_dict['model_score'])\n",
    "    max_index = train_log_dict['model_score'].index(max_score)\n",
    "    best_model = train_log_dict['model_fit'][max_index]\n",
    "    name = train_log_dict['model_name'][max_index]\n",
    "\n",
    "    return best_model, name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, Y_train, model):\n",
    "\n",
    "    model_fitted = model.fit(X_train, Y_train)\n",
    "    return model_fitted\n",
    "\n",
    "def validate(X_test, Y_test, model_fitted, ):\n",
    "\n",
    "    auc_score = roc_auc_score(Y_test, model_fitted.predict_proba(X_test))\n",
    "\n",
    "\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(X_train, X_test, Y_train,  Y_test):\n",
    "    \n",
    "\n",
    "    # Initiate models\n",
    "    knn = model_knn\n",
    "    dt = model_dt\n",
    "    mlp = model_mlp\n",
    "    \n",
    "    # Initiate logs\n",
    "    train_log_dict = {'model': [knn, dt, mlp],\n",
    "                      'model_name': [],\n",
    "                      'model_score': []}\n",
    "\n",
    "\n",
    "    # Try Each models\n",
    "    for model in train_log_dict['model']:\n",
    "        base_model = model()\n",
    "        train_log_dict['model_name'].append(base_model.__class__.__name__)\n",
    "        print(f'Fitting {base_model.__class__.__name__}')\n",
    "\n",
    "        # Train\n",
    "        fitted_model = fit(X_train, Y_train, base_model)\n",
    "\n",
    "        # Validate\n",
    "        score = validate(X_test, Y_test, fitted_model)\n",
    "        train_log_dict['model_score'].append(score)\n",
    "\n",
    "    best_model, best_report, best_threshold, name = select_model(train_log_dict)\n",
    "    \n",
    "    print(\n",
    "        f\"Model: {name}, Score: {best_report['f1-score']['macro avg']}\")\n",
    "    joblib.dump(best_model, 'E:\\\\projects\\\\plds_latihan\\\\pipeline\\\\mantab_model.pkl')\n",
    "    joblib.dump(best_threshold, 'E:\\\\projects\\\\plds_latihan\\\\pipeline\\\\threshold.pkl')\n",
    "    joblib.dump(train_log_dict, 'E:\\\\projects\\\\plds_latihan\\\\pipeline\\\\train_log.pkl')\n",
    "    print(f'\\n {best_report}')\n",
    "    \n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\n",
    "    X_train = joblib.load(\"E:\\\\projects\\\\plds_teamc\\\\output\\\\X_train_3.pkl\")\n",
    "    X_test = joblib.load(\"E:\\\\projects\\\\plds_teamc\\\\output\\\\X_test_3.pkl\")\n",
    "    Y_train = joblib.load(\"E:\\\\projects\\\\plds_teamc\\\\output\\\\Y_train_3.pkl\")\n",
    "    Y_test = joblib.load(\"E:\\\\projects\\\\plds_teamc\\\\output\\\\Y_test_3.pkl\")\n",
    "\n",
    "    return X_train, X_test, Y_train,  Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train,  Y_test= load_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Using cached keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mhpra\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=142999fb40cb7d8ec140c7223b31152e1f32e50728be5a93b5049a99c4ac1fc1\n",
      "  Stored in directory: c:\\users\\mhpra\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.1.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 oauthlib-3.2.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\plds_teamc\\notebook\\model_exploration_2a.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/plds_teamc/notebook/model_exploration_2a.ipynb#ch0000025?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m roc_curve, auc, precision_recall_curve, classification_report, average_precision_score\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/projects/plds_teamc/notebook/model_exploration_2a.ipynb#ch0000025?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxgb\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/plds_teamc/notebook/model_exploration_2a.ipynb#ch0000025?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_importance, to_graphviz\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/plds_teamc/notebook/model_exploration_2a.ipynb#ch0000025?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, classification_report, average_precision_score\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, to_graphviz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, roc_auc):\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve (area = %0.6f)' % roc_auc)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pr(recall,precision,average_precision):\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall: {0:0.6f}'.format(average_precision))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_learning_curve(results,epochs):\n",
    "    x_axis = range(0, epochs)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['logloss'], label='logloss-Train')\n",
    "    ax.plot(x_axis, results['validation_1']['logloss'], label='logloss-Test')\n",
    "    ax.plot(x_axis, results['validation_0']['auc'], label='auc-Train')\n",
    "    ax.plot(x_axis, results['validation_1']['auc'], label='auc-Test')\n",
    "    ax.legend()\n",
    "    plt.ylabel('Log Loss/AUC')\n",
    "    plt.title('XGBoost Log Loss and AUC evolution')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_xgboost_and_calculate_auc( X_train, X_test, Y_train, Y_test ,\n",
    "                                  target='target',\n",
    "                                  drop='variable_to_find_and_exclude',\n",
    "                                  w=1,\n",
    "                                  plot_learning=False,\n",
    "                                  plot_variables=False,\n",
    "                                  plot_ROC_PR=False,\n",
    "                                  plot_confusion=False,\n",
    "                                  plot_graph_tree=False,\n",
    "                                  learning_rate=0.05,\n",
    "                                  max_depth=10,\n",
    "                                  esr=10,\n",
    "                                  CV=True,\n",
    "                                  title='',\n",
    "                                  plot_all=False,\n",
    "                                  ensembler=False,\n",
    "                                  test_size=.2):\n",
    "    '''\n",
    "    Generic function to run xgboost to test the added changes and plot roc, learning and others and save the model.\n",
    "    '''\n",
    "   \n",
    "        \n",
    "    clf = xgb.XGBClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=1000,\n",
    "        max_depth=4,\n",
    "        min_child_weight=4,\n",
    "        gamma=0.6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=5e-05,\n",
    "        objective='binary:logistic',\n",
    "        nthread=20,\n",
    "        scale_pos_weight=w,\n",
    "        seed=27)\n",
    "\n",
    "    eval_set = [(X_train, Y_train), (X_test, Y_test)]\n",
    "\n",
    "    if plot_all:\n",
    "        plot_learning=True\n",
    "        plot_variables=True\n",
    "        plot_ROC_PR=True\n",
    "        plot_confusion=True\n",
    "        plot_graph_tree=True\n",
    "        \n",
    "    if CV:\n",
    "        X = pd.concat([X_train,X_test])\n",
    "        y = pd.concat([Y_train,Y_test])\n",
    "        xgb_param = clf.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X.values, y.values)\n",
    "        cvresult = xgb.cv(xgb_param,\n",
    "                          xgtrain,\n",
    "                          num_boost_round=clf.get_params()['n_estimators'],\n",
    "                          nfold=5,\n",
    "                          metrics='auc',\n",
    "                          early_stopping_rounds=esr)\n",
    "        print(cvresult.tail(1))\n",
    "        clf.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    clf.fit(X_train,\n",
    "            Y_train,\n",
    "            early_stopping_rounds=25,\n",
    "            eval_metric=['auc','error','logloss'],\n",
    "            eval_set=eval_set,\n",
    "            verbose=False)\n",
    "\n",
    "    Y_pred = clf.predict_proba(X_test)\n",
    "    y_true = np.array(Y_test)\n",
    "    y_scores = Y_pred[:, 1]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(Y_test, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    average_precision = average_precision_score(Y_test, y_scores)\n",
    "    precision, recall, _ = precision_recall_curve(Y_test, y_scores)\n",
    "    \n",
    "    if plot_ROC_PR:\n",
    "        plot_roc(fpr, tpr, roc_auc)\n",
    "        plot_pr(recall,precision,average_precision)\n",
    "    else:\n",
    "        print('Area under ROC: %0.6f' % roc_auc)\n",
    "\n",
    "    if plot_graph_tree:\n",
    "        xgb.plot_tree(clf, rankdir='LR')\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(150, 100)\n",
    "\n",
    "    if plot_learning:\n",
    "        results = clf.evals_result()\n",
    "        epochs = len(results['validation_0']['error'])\n",
    "\n",
    "    if plot_variables:\n",
    "        xgb.plot_importance(clf,max_num_features=20,importance_type='gain',xlabel='gain')\n",
    "\n",
    "    if plot_confusion:\n",
    "        print('\\n', classification_report(y_true, y_scores.round()))\n",
    "\n",
    "    if title:\n",
    "        timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        path = 'E:\\\\projects\\\\plds_teamc\\\\model\\\\'\n",
    "        save_model(model=clf,path=path,title=str(title))\n",
    "        \n",
    "    if ensembler:\n",
    "        return Y_test, y_scores\n",
    "\n",
    "    print('-------------END EXECUTION-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_test, y_scores = run_xgboost_and_calculate_auc(  X_train, X_test, Y_train, Y_test ,target='Survived',plot_all=True,ensembler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build VT-CNN2 Neural Net model using Keras primitives -- \n",
    "#  - Reshape [N,2,128] to [N,1,2,128] on input\n",
    "#  - Pass through 2 2DConv/ReLu layers\n",
    "#  - Pass through 2 Dense layers (ReLu and Softmax)\n",
    "#  - Perform categorical cross entropy optimization\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.callbacks\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "from tensorflow.keras.layers import PReLU\n",
    "from tensorflow.keras.layers import MaxPooling2D \n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "model = models.Sequential()\n",
    "#model.add(Reshape([1]+in_shp, input_shape=in_shp))\n",
    "model.add(Dense(16, name=\"dense1\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dense(32, name=\"dense2\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, name=\"dense3\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dense(128, name=\"dense4\", kernel_initializer=\"he_normal\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, name=\"dense5\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, name=\"dense6\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dense(64, name=\"dense7\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, name=\"dense8\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dense(16, name=\"dense9\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Dense(1, name=\"dense10\", kernel_initializer=\"he_normal\", activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '> 50'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\plds_teamc\\notebook\\model_exploration_2a.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/projects/plds_teamc/notebook/model_exploration_2a.ipynb#ch0000011?line=0'>1</a>\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(X_train)\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/plds_teamc/notebook/model_exploration_2a.ipynb#ch0000011?line=1'>2</a>\u001b[0m X_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(X_test)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/plds_teamc/notebook/model_exploration_2a.ipynb#ch0000011?line=2'>3</a>\u001b[0m Y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(Y_train)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '> 50'"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "Y_train = np.asarray(Y_train).astype(np.float32)\n",
    "Y_test = np.asarray(Y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 227262 entries, 110780 to 176986\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                                          Non-Null Count   Dtype  \n",
      "---  ------                                                          --------------   -----  \n",
      " 0   Patient Age at Treatment                                        227262 non-null  int64  \n",
      " 1   Total Number of Previous treatments, Both IVF and DI at clinic  227262 non-null  int64  \n",
      " 2   Total Number of Previous IVF cycles                             227262 non-null  int64  \n",
      " 3   Total number of IVF pregnancies                                 227262 non-null  int64  \n",
      " 4   Type of Infertility - Female Primary                            227262 non-null  int64  \n",
      " 5   Type of Infertility - Female Secondary                          227262 non-null  int64  \n",
      " 6   Type of Infertility - Male Primary                              227262 non-null  int64  \n",
      " 7   Type of Infertility - Male Secondary                            227262 non-null  int64  \n",
      " 8   Type of Infertility -Couple Primary                             227262 non-null  int64  \n",
      " 9   Type of Infertility -Couple Secondary                           227262 non-null  int64  \n",
      " 10  Cause  of Infertility - Tubal disease                           227262 non-null  int64  \n",
      " 11  Cause of Infertility - Ovulatory Disorder                       227262 non-null  int64  \n",
      " 12  Cause of Infertility - Male Factor                              227262 non-null  int64  \n",
      " 13  Cause of Infertility - Patient Unexplained                      227262 non-null  int64  \n",
      " 14  Cause of Infertility - Endometriosis                            227262 non-null  int64  \n",
      " 15  Cause of Infertility - Cervical factors                         227262 non-null  int64  \n",
      " 16  Cause of Infertility - Female Factors                           227262 non-null  int64  \n",
      " 17  Cause of Infertility - Partner Sperm Concentration              227262 non-null  int64  \n",
      " 18  Cause of Infertility -  Partner Sperm Morphology                227262 non-null  int64  \n",
      " 19  Causes of Infertility - Partner Sperm Motility                  227262 non-null  int64  \n",
      " 20  Cause of Infertility -  Partner Sperm Immunological factors     227262 non-null  int64  \n",
      " 21  Embryos Transfered                                              227262 non-null  float64\n",
      " 22  Total Embryos Created                                           227262 non-null  object \n",
      "dtypes: float64(1), int64(21), object(1)\n",
      "memory usage: 41.6+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "222/222 - 6s - loss: 0.8200 - accuracy: 0.6987 - val_loss: 0.5221 - val_accuracy: 0.7397 - 6s/epoch - 28ms/step\n",
      "Epoch 2/100\n",
      "222/222 - 4s - loss: 0.5308 - accuracy: 0.7376 - val_loss: 0.5122 - val_accuracy: 0.7416 - 4s/epoch - 20ms/step\n",
      "Epoch 3/100\n",
      "222/222 - 4s - loss: 0.5221 - accuracy: 0.7381 - val_loss: 0.5093 - val_accuracy: 0.7438 - 4s/epoch - 19ms/step\n",
      "Epoch 4/100\n",
      "222/222 - 4s - loss: 0.5190 - accuracy: 0.7388 - val_loss: 0.5086 - val_accuracy: 0.7419 - 4s/epoch - 19ms/step\n",
      "Epoch 5/100\n",
      "222/222 - 4s - loss: 0.5179 - accuracy: 0.7394 - val_loss: 0.5085 - val_accuracy: 0.7423 - 4s/epoch - 19ms/step\n",
      "Epoch 6/100\n",
      "222/222 - 4s - loss: 0.5164 - accuracy: 0.7393 - val_loss: 0.5110 - val_accuracy: 0.7452 - 4s/epoch - 19ms/step\n",
      "Epoch 7/100\n",
      "222/222 - 4s - loss: 0.5158 - accuracy: 0.7393 - val_loss: 0.5091 - val_accuracy: 0.7449 - 4s/epoch - 19ms/step\n",
      "Epoch 8/100\n",
      "222/222 - 4s - loss: 0.5150 - accuracy: 0.7400 - val_loss: 0.5083 - val_accuracy: 0.7397 - 4s/epoch - 19ms/step\n",
      "Epoch 9/100\n",
      "222/222 - 4s - loss: 0.5143 - accuracy: 0.7402 - val_loss: 0.5081 - val_accuracy: 0.7397 - 4s/epoch - 19ms/step\n",
      "Epoch 10/100\n",
      "222/222 - 4s - loss: 0.5139 - accuracy: 0.7400 - val_loss: 0.5087 - val_accuracy: 0.7442 - 4s/epoch - 19ms/step\n",
      "Epoch 11/100\n",
      "222/222 - 4s - loss: 0.5132 - accuracy: 0.7414 - val_loss: 0.5080 - val_accuracy: 0.7414 - 4s/epoch - 19ms/step\n",
      "Epoch 12/100\n",
      "222/222 - 4s - loss: 0.5132 - accuracy: 0.7406 - val_loss: 0.5086 - val_accuracy: 0.7433 - 4s/epoch - 19ms/step\n",
      "Epoch 13/100\n",
      "222/222 - 4s - loss: 0.5131 - accuracy: 0.7411 - val_loss: 0.5082 - val_accuracy: 0.7403 - 4s/epoch - 19ms/step\n",
      "Epoch 14/100\n",
      "222/222 - 4s - loss: 0.5127 - accuracy: 0.7417 - val_loss: 0.5082 - val_accuracy: 0.7438 - 4s/epoch - 19ms/step\n",
      "Epoch 15/100\n",
      "222/222 - 4s - loss: 0.5126 - accuracy: 0.7410 - val_loss: 0.5103 - val_accuracy: 0.7460 - 4s/epoch - 19ms/step\n",
      "Epoch 16/100\n",
      "222/222 - 4s - loss: 0.5121 - accuracy: 0.7412 - val_loss: 0.5085 - val_accuracy: 0.7381 - 4s/epoch - 19ms/step\n",
      "Epoch 17/100\n",
      "222/222 - 4s - loss: 0.5122 - accuracy: 0.7415 - val_loss: 0.5079 - val_accuracy: 0.7407 - 4s/epoch - 19ms/step\n",
      "Epoch 18/100\n",
      "222/222 - 4s - loss: 0.5123 - accuracy: 0.7411 - val_loss: 0.5089 - val_accuracy: 0.7448 - 4s/epoch - 19ms/step\n",
      "Epoch 19/100\n",
      "222/222 - 5s - loss: 0.5118 - accuracy: 0.7413 - val_loss: 0.5083 - val_accuracy: 0.7417 - 5s/epoch - 21ms/step\n",
      "Epoch 20/100\n",
      "222/222 - 5s - loss: 0.5124 - accuracy: 0.7404 - val_loss: 0.5082 - val_accuracy: 0.7434 - 5s/epoch - 21ms/step\n",
      "Epoch 21/100\n",
      "222/222 - 5s - loss: 0.5118 - accuracy: 0.7414 - val_loss: 0.5083 - val_accuracy: 0.7426 - 5s/epoch - 20ms/step\n",
      "Epoch 22/100\n",
      "222/222 - 5s - loss: 0.5118 - accuracy: 0.7415 - val_loss: 0.5085 - val_accuracy: 0.7372 - 5s/epoch - 21ms/step\n",
      "Epoch 23/100\n",
      "222/222 - 5s - loss: 0.5117 - accuracy: 0.7413 - val_loss: 0.5089 - val_accuracy: 0.7362 - 5s/epoch - 21ms/step\n",
      "Epoch 24/100\n",
      "222/222 - 5s - loss: 0.5115 - accuracy: 0.7410 - val_loss: 0.5089 - val_accuracy: 0.7450 - 5s/epoch - 20ms/step\n",
      "Epoch 25/100\n",
      "222/222 - 5s - loss: 0.5115 - accuracy: 0.7417 - val_loss: 0.5082 - val_accuracy: 0.7431 - 5s/epoch - 21ms/step\n",
      "Epoch 26/100\n",
      "222/222 - 4s - loss: 0.5114 - accuracy: 0.7416 - val_loss: 0.5091 - val_accuracy: 0.7367 - 4s/epoch - 20ms/step\n",
      "Epoch 27/100\n",
      "222/222 - 4s - loss: 0.5114 - accuracy: 0.7412 - val_loss: 0.5079 - val_accuracy: 0.7409 - 4s/epoch - 18ms/step\n",
      "Epoch 28/100\n",
      "222/222 - 4s - loss: 0.5114 - accuracy: 0.7417 - val_loss: 0.5083 - val_accuracy: 0.7432 - 4s/epoch - 19ms/step\n",
      "Epoch 29/100\n",
      "222/222 - 5s - loss: 0.5114 - accuracy: 0.7417 - val_loss: 0.5086 - val_accuracy: 0.7385 - 5s/epoch - 23ms/step\n",
      "Epoch 30/100\n",
      "222/222 - 4s - loss: 0.5114 - accuracy: 0.7415 - val_loss: 0.5080 - val_accuracy: 0.7427 - 4s/epoch - 20ms/step\n",
      "Epoch 31/100\n",
      "222/222 - 5s - loss: 0.5111 - accuracy: 0.7420 - val_loss: 0.5087 - val_accuracy: 0.7447 - 5s/epoch - 20ms/step\n",
      "Epoch 32/100\n",
      "222/222 - 4s - loss: 0.5108 - accuracy: 0.7418 - val_loss: 0.5081 - val_accuracy: 0.7387 - 4s/epoch - 19ms/step\n",
      "Epoch 33/100\n",
      "222/222 - 4s - loss: 0.5110 - accuracy: 0.7421 - val_loss: 0.5106 - val_accuracy: 0.7352 - 4s/epoch - 20ms/step\n",
      "Epoch 34/100\n",
      "222/222 - 4s - loss: 0.5110 - accuracy: 0.7419 - val_loss: 0.5095 - val_accuracy: 0.7451 - 4s/epoch - 20ms/step\n",
      "Epoch 35/100\n",
      "222/222 - 4s - loss: 0.5109 - accuracy: 0.7419 - val_loss: 0.5110 - val_accuracy: 0.7454 - 4s/epoch - 19ms/step\n",
      "Epoch 36/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7419 - val_loss: 0.5086 - val_accuracy: 0.7441 - 4s/epoch - 19ms/step\n",
      "Epoch 37/100\n",
      "222/222 - 4s - loss: 0.5107 - accuracy: 0.7417 - val_loss: 0.5081 - val_accuracy: 0.7426 - 4s/epoch - 18ms/step\n",
      "Epoch 38/100\n",
      "222/222 - 4s - loss: 0.5108 - accuracy: 0.7420 - val_loss: 0.5079 - val_accuracy: 0.7399 - 4s/epoch - 18ms/step\n",
      "Epoch 39/100\n",
      "222/222 - 4s - loss: 0.5110 - accuracy: 0.7416 - val_loss: 0.5102 - val_accuracy: 0.7458 - 4s/epoch - 18ms/step\n",
      "Epoch 40/100\n",
      "222/222 - 4s - loss: 0.5109 - accuracy: 0.7417 - val_loss: 0.5081 - val_accuracy: 0.7411 - 4s/epoch - 18ms/step\n",
      "Epoch 41/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7418 - val_loss: 0.5091 - val_accuracy: 0.7406 - 4s/epoch - 18ms/step\n",
      "Epoch 42/100\n",
      "222/222 - 4s - loss: 0.5110 - accuracy: 0.7423 - val_loss: 0.5081 - val_accuracy: 0.7436 - 4s/epoch - 18ms/step\n",
      "Epoch 43/100\n",
      "222/222 - 4s - loss: 0.5108 - accuracy: 0.7417 - val_loss: 0.5090 - val_accuracy: 0.7452 - 4s/epoch - 18ms/step\n",
      "Epoch 44/100\n",
      "222/222 - 4s - loss: 0.5107 - accuracy: 0.7420 - val_loss: 0.5091 - val_accuracy: 0.7369 - 4s/epoch - 18ms/step\n",
      "Epoch 45/100\n",
      "222/222 - 4s - loss: 0.5108 - accuracy: 0.7424 - val_loss: 0.5106 - val_accuracy: 0.7456 - 4s/epoch - 18ms/step\n",
      "Epoch 46/100\n",
      "222/222 - 4s - loss: 0.5108 - accuracy: 0.7421 - val_loss: 0.5086 - val_accuracy: 0.7439 - 4s/epoch - 18ms/step\n",
      "Epoch 47/100\n",
      "222/222 - 4s - loss: 0.5105 - accuracy: 0.7421 - val_loss: 0.5082 - val_accuracy: 0.7392 - 4s/epoch - 18ms/step\n",
      "Epoch 48/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7418 - val_loss: 0.5094 - val_accuracy: 0.7457 - 4s/epoch - 18ms/step\n",
      "Epoch 49/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7424 - val_loss: 0.5079 - val_accuracy: 0.7403 - 4s/epoch - 18ms/step\n",
      "Epoch 50/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7421 - val_loss: 0.5083 - val_accuracy: 0.7383 - 4s/epoch - 18ms/step\n",
      "Epoch 51/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7419 - val_loss: 0.5104 - val_accuracy: 0.7459 - 4s/epoch - 18ms/step\n",
      "Epoch 52/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7421 - val_loss: 0.5086 - val_accuracy: 0.7441 - 4s/epoch - 18ms/step\n",
      "Epoch 53/100\n",
      "222/222 - 4s - loss: 0.5107 - accuracy: 0.7421 - val_loss: 0.5080 - val_accuracy: 0.7426 - 4s/epoch - 18ms/step\n",
      "Epoch 54/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7420 - val_loss: 0.5085 - val_accuracy: 0.7439 - 4s/epoch - 18ms/step\n",
      "Epoch 55/100\n",
      "222/222 - 4s - loss: 0.5105 - accuracy: 0.7423 - val_loss: 0.5078 - val_accuracy: 0.7412 - 4s/epoch - 19ms/step\n",
      "Epoch 56/100\n",
      "222/222 - 4s - loss: 0.5105 - accuracy: 0.7422 - val_loss: 0.5093 - val_accuracy: 0.7452 - 4s/epoch - 19ms/step\n",
      "Epoch 57/100\n",
      "222/222 - 4s - loss: 0.5104 - accuracy: 0.7418 - val_loss: 0.5084 - val_accuracy: 0.7442 - 4s/epoch - 19ms/step\n",
      "Epoch 58/100\n",
      "222/222 - 5s - loss: 0.5105 - accuracy: 0.7415 - val_loss: 0.5105 - val_accuracy: 0.7458 - 5s/epoch - 21ms/step\n",
      "Epoch 59/100\n",
      "222/222 - 5s - loss: 0.5104 - accuracy: 0.7419 - val_loss: 0.5081 - val_accuracy: 0.7424 - 5s/epoch - 21ms/step\n",
      "Epoch 60/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7420 - val_loss: 0.5082 - val_accuracy: 0.7394 - 4s/epoch - 19ms/step\n",
      "Epoch 61/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7420 - val_loss: 0.5081 - val_accuracy: 0.7432 - 4s/epoch - 19ms/step\n",
      "Epoch 62/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7423 - val_loss: 0.5079 - val_accuracy: 0.7391 - 4s/epoch - 19ms/step\n",
      "Epoch 63/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7416 - val_loss: 0.5082 - val_accuracy: 0.7416 - 4s/epoch - 20ms/step\n",
      "Epoch 64/100\n",
      "222/222 - 4s - loss: 0.5106 - accuracy: 0.7426 - val_loss: 0.5096 - val_accuracy: 0.7457 - 4s/epoch - 18ms/step\n",
      "Epoch 65/100\n",
      "222/222 - 4s - loss: 0.5107 - accuracy: 0.7424 - val_loss: 0.5080 - val_accuracy: 0.7392 - 4s/epoch - 20ms/step\n",
      "Epoch 66/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7417 - val_loss: 0.5082 - val_accuracy: 0.7430 - 4s/epoch - 19ms/step\n",
      "Epoch 67/100\n",
      "222/222 - 4s - loss: 0.5103 - accuracy: 0.7421 - val_loss: 0.5099 - val_accuracy: 0.7456 - 4s/epoch - 18ms/step\n",
      "Epoch 68/100\n",
      "222/222 - 4s - loss: 0.5103 - accuracy: 0.7419 - val_loss: 0.5085 - val_accuracy: 0.7420 - 4s/epoch - 18ms/step\n",
      "Epoch 69/100\n",
      "222/222 - 4s - loss: 0.5105 - accuracy: 0.7421 - val_loss: 0.5080 - val_accuracy: 0.7423 - 4s/epoch - 20ms/step\n",
      "Epoch 70/100\n",
      "222/222 - 4s - loss: 0.5104 - accuracy: 0.7420 - val_loss: 0.5083 - val_accuracy: 0.7397 - 4s/epoch - 20ms/step\n",
      "Epoch 71/100\n",
      "222/222 - 4s - loss: 0.5104 - accuracy: 0.7423 - val_loss: 0.5084 - val_accuracy: 0.7436 - 4s/epoch - 19ms/step\n",
      "Epoch 72/100\n",
      "222/222 - 4s - loss: 0.5104 - accuracy: 0.7420 - val_loss: 0.5079 - val_accuracy: 0.7422 - 4s/epoch - 19ms/step\n",
      "Epoch 73/100\n",
      "222/222 - 5s - loss: 0.5105 - accuracy: 0.7417 - val_loss: 0.5094 - val_accuracy: 0.7456 - 5s/epoch - 21ms/step\n",
      "Epoch 74/100\n",
      "222/222 - 4s - loss: 0.5104 - accuracy: 0.7420 - val_loss: 0.5090 - val_accuracy: 0.7372 - 4s/epoch - 20ms/step\n",
      "Epoch 75/100\n",
      "222/222 - 5s - loss: 0.5103 - accuracy: 0.7423 - val_loss: 0.5090 - val_accuracy: 0.7436 - 5s/epoch - 22ms/step\n",
      "Epoch 76/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7425 - val_loss: 0.5083 - val_accuracy: 0.7420 - 4s/epoch - 20ms/step\n",
      "Epoch 77/100\n",
      "222/222 - 4s - loss: 0.5103 - accuracy: 0.7425 - val_loss: 0.5081 - val_accuracy: 0.7388 - 4s/epoch - 19ms/step\n",
      "Epoch 78/100\n",
      "222/222 - 4s - loss: 0.5103 - accuracy: 0.7422 - val_loss: 0.5084 - val_accuracy: 0.7390 - 4s/epoch - 19ms/step\n",
      "Epoch 79/100\n",
      "222/222 - 4s - loss: 0.5104 - accuracy: 0.7424 - val_loss: 0.5079 - val_accuracy: 0.7405 - 4s/epoch - 19ms/step\n",
      "Epoch 80/100\n",
      "222/222 - 4s - loss: 0.5101 - accuracy: 0.7424 - val_loss: 0.5106 - val_accuracy: 0.7458 - 4s/epoch - 18ms/step\n",
      "Epoch 81/100\n",
      "222/222 - 4s - loss: 0.5105 - accuracy: 0.7423 - val_loss: 0.5083 - val_accuracy: 0.7430 - 4s/epoch - 18ms/step\n",
      "Epoch 82/100\n",
      "222/222 - 4s - loss: 0.5105 - accuracy: 0.7416 - val_loss: 0.5088 - val_accuracy: 0.7448 - 4s/epoch - 18ms/step\n",
      "Epoch 83/100\n",
      "222/222 - 4s - loss: 0.5105 - accuracy: 0.7421 - val_loss: 0.5079 - val_accuracy: 0.7417 - 4s/epoch - 19ms/step\n",
      "Epoch 84/100\n",
      "222/222 - 4s - loss: 0.5103 - accuracy: 0.7423 - val_loss: 0.5079 - val_accuracy: 0.7409 - 4s/epoch - 18ms/step\n",
      "Epoch 85/100\n",
      "222/222 - 4s - loss: 0.5105 - accuracy: 0.7422 - val_loss: 0.5083 - val_accuracy: 0.7435 - 4s/epoch - 18ms/step\n",
      "Epoch 86/100\n",
      "222/222 - 4s - loss: 0.5103 - accuracy: 0.7422 - val_loss: 0.5080 - val_accuracy: 0.7426 - 4s/epoch - 18ms/step\n",
      "Epoch 87/100\n",
      "222/222 - 4s - loss: 0.5103 - accuracy: 0.7423 - val_loss: 0.5083 - val_accuracy: 0.7437 - 4s/epoch - 19ms/step\n",
      "Epoch 88/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7417 - val_loss: 0.5085 - val_accuracy: 0.7367 - 4s/epoch - 18ms/step\n",
      "Epoch 89/100\n",
      "222/222 - 4s - loss: 0.5103 - accuracy: 0.7427 - val_loss: 0.5083 - val_accuracy: 0.7435 - 4s/epoch - 18ms/step\n",
      "Epoch 90/100\n",
      "222/222 - 4s - loss: 0.5103 - accuracy: 0.7424 - val_loss: 0.5082 - val_accuracy: 0.7431 - 4s/epoch - 19ms/step\n",
      "Epoch 91/100\n",
      "222/222 - 4s - loss: 0.5101 - accuracy: 0.7425 - val_loss: 0.5082 - val_accuracy: 0.7435 - 4s/epoch - 18ms/step\n",
      "Epoch 92/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7425 - val_loss: 0.5094 - val_accuracy: 0.7456 - 4s/epoch - 18ms/step\n",
      "Epoch 93/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7422 - val_loss: 0.5078 - val_accuracy: 0.7416 - 4s/epoch - 18ms/step\n",
      "Epoch 94/100\n",
      "222/222 - 4s - loss: 0.5104 - accuracy: 0.7421 - val_loss: 0.5086 - val_accuracy: 0.7447 - 4s/epoch - 18ms/step\n",
      "Epoch 95/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7421 - val_loss: 0.5085 - val_accuracy: 0.7406 - 4s/epoch - 18ms/step\n",
      "Epoch 96/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7423 - val_loss: 0.5082 - val_accuracy: 0.7423 - 4s/epoch - 19ms/step\n",
      "Epoch 97/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7422 - val_loss: 0.5081 - val_accuracy: 0.7409 - 4s/epoch - 20ms/step\n",
      "Epoch 98/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7428 - val_loss: 0.5083 - val_accuracy: 0.7438 - 4s/epoch - 19ms/step\n",
      "Epoch 99/100\n",
      "222/222 - 4s - loss: 0.5100 - accuracy: 0.7424 - val_loss: 0.5086 - val_accuracy: 0.7443 - 4s/epoch - 19ms/step\n",
      "Epoch 100/100\n",
      "222/222 - 4s - loss: 0.5102 - accuracy: 0.7424 - val_loss: 0.5081 - val_accuracy: 0.7414 - 4s/epoch - 19ms/step\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 100     # number of epochs to train on\n",
    "batch_size = 1024 # training batch size\n",
    "filepath = 'E:\\\\projects\\\\plds_teamc\\\\data\\\\HARRY.h5'\n",
    "\n",
    "history = model.fit(X_train,\n",
    "    Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=nb_epoch,\n",
    "    verbose=2,\n",
    "    validation_data=(X_test,Y_test),\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:   \n",
    "# #https://stackoverflow.com/questions/41061457/keras-how-to-save-the-training-history-attribute-of-the-history-object  \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_csv_file = 'E:\\\\projects\\\\plds_teamc\\\\data\\\\history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\projects\\\\plds_teamc\\\\data\\\\acc_threshold.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_threshold = hist_df[\"accuracy\"].mean()\n",
    "joblib.dump(acc_threshold, 'E:\\\\projects\\\\plds_teamc\\\\data\\\\acc_threshold.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = KNeighborsClassifier(n_neighbors=50)\n",
    "#base_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#base_model = MLPClassifier(hidden_layer_sizes=(100,300,150), random_state=42, max_iter=300)\n",
    "\n",
    "\n",
    "model_fitted = base_model.fit(X_train, Y_train)\n",
    "\n",
    "#auc_score = roc_auc_score(Y_test, model_fitted.predict(X_test))\n",
    "auc_score = roc_auc_score(Y_test, model_fitted.predict(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient Age at Treatment                                          0.0\n",
       "Total Number of Previous treatments, Both IVF and DI at clinic    0.0\n",
       "Total Number of Previous IVF cycles                               0.0\n",
       "Total number of IVF pregnancies                                   0.0\n",
       "Type of Infertility - Female Primary                              0.0\n",
       "Type of Infertility - Female Secondary                            0.0\n",
       "Type of Infertility - Male Primary                                0.0\n",
       "Type of Infertility - Male Secondary                              0.0\n",
       "Type of Infertility -Couple Primary                               0.0\n",
       "Type of Infertility -Couple Secondary                             0.0\n",
       "Cause  of Infertility - Tubal disease                             0.0\n",
       "Cause of Infertility - Ovulatory Disorder                         0.0\n",
       "Cause of Infertility - Male Factor                                1.0\n",
       "Cause of Infertility - Patient Unexplained                        0.0\n",
       "Cause of Infertility - Endometriosis                              0.0\n",
       "Cause of Infertility - Cervical factors                           0.0\n",
       "Cause of Infertility - Female Factors                             0.0\n",
       "Cause of Infertility - Partner Sperm Concentration                0.0\n",
       "Cause of Infertility -  Partner Sperm Morphology                  0.0\n",
       "Causes of Infertility - Partner Sperm Motility                    0.0\n",
       "Cause of Infertility -  Partner Sperm Immunological factors       0.0\n",
       "Embryos Transfered                                                2.0\n",
       "Total Embryos Created                                             3.0\n",
       "Name: 166945, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train,  Y_test= load_dataset()\n",
    "text=X_train.iloc[1000]\n",
    "text.to_csv('E:\\projects\\plds_teamc\\data\\sample2.csv')  \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\projects\\plds_teamc\\data\\assets\n"
     ]
    }
   ],
   "source": [
    "#joblib.dump(model, 'E:\\\\projects\\\\plds_teamc\\\\data\\\\mantab_model.pkl')\n",
    "model.save('E:\\\\projects\\\\plds_teamc\\\\data\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_predict(text, model, threshold):\n",
    "    text = text[[text.columns[1]]]\n",
    "    text = np.asarray(text).astype(np.float32).T\n",
    "    text = text.reshape(-1, 23)\n",
    "    code2rel = {0: 'Tidak berhasil', 1: 'Berhasil'}\n",
    "    \n",
    "    proba = model.predict(text)\n",
    "    predict = 1 if proba > threshold else 0\n",
    "    print(f\"{code2rel[predict]}, dengan akurasi {proba}\")\n",
    "\n",
    "    return code2rel[predict], proba\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('E:\\\\projects\\\\plds_teamc\\\\data\\\\')\n",
    "threshold = joblib.load('E:\\\\projects\\\\plds_teamc\\\\data\\\\acc_threshold.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv(\"E:\\projects\\plds_teamc\\data\\sample2.csv\") \n",
    "#text = np.asarray(text).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n",
      "Tidak berhasil, dengan akurasi [[0.3675122]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "proba = main_predict(text, model, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f9ce6eba129c4e9adeb7a9652474f34792e333d7d887e515c6f6483448857cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
